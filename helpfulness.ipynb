{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "helpfulness.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1lu-o4UsQ0T"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "import pandas as pd                                  \n",
        "import numpy as np                                   \n",
        "import random                                        \n",
        "from nltk.stem.porter import PorterStemmer           \n",
        "import string                                        \n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Reviews.csv')"
      ],
      "metadata": {
        "id": "Dhd6kckKvLSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count non-unique review texts\n",
        "dupe_texts = data.duplicated(subset=['Text'])\n",
        "dupe_texts[dupe_texts == True].count()"
      ],
      "metadata": {
        "id": "AnQch9VAvLyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select just the unique reviews\n",
        "data = data.drop_duplicates(subset=['Text'])"
      ],
      "metadata": {
        "id": "24VidaCXvMT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check counts and missing values\n",
        "data.info()"
      ],
      "metadata": {
        "id": "oiPFMEyavMjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Text_len'] = data['Text'].apply(lambda x: len(x))\n",
        "data.head()"
      ],
      "metadata": {
        "id": "hJcYEB01vMwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatize data\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def lemmatize(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    word_list = nltk.word_tokenize(text)\n",
        "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w, pos='v') for w in word_list])\n",
        "    return lemmatized_output\n",
        "\n",
        "data['Text'] = data['Text'].apply(lemmatize)"
      ],
      "metadata": {
        "id": "iB4J7zGMvM86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-val-test split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=val_len1,\n",
        "                                                    random_state=123)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1_train, y1_train, \n",
        "                                                test_size=val_len1,\n",
        "                                                random_state=123)"
      ],
      "metadata": {
        "id": "KIw-TR_7vN4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing Stop Words\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "stop_list = stopwords.words('english')\n",
        "stop_list += list(string.punctuation)\n",
        "stop_list += ['br', '.<', '..', '...', '``', \"''\", '--']"
      ],
      "metadata": {
        "id": "tKqGGmxSvOJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a CountVectorizer-RandomForest pipeline (~ 3.5 min.)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipe_bigram_rf = Pipeline([('vectorizer', CountVectorizer(analyzer='word', \n",
        "                                                          ngram_range=(2, 2), \n",
        "                                                          stop_words=stop_list, \n",
        "                                                          max_features=100)),\n",
        "                        ('forest', RandomForestClassifier(n_estimators=100,\n",
        "                                                          n_jobs=-1))])"
      ],
      "metadata": {
        "id": "JeBfodsfvOaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_bigram_rf.fit(X1_train, y1_train)"
      ],
      "metadata": {
        "id": "c2i-WPDTvOsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "y1_pred_train = pipe_bigram_rf.predict(X1_train)\n",
        "print('Training accuracy:', accuracy_score(y1_train, y1_pred_train))"
      ],
      "metadata": {
        "id": "uhQwEQXSvPBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b3hMh0PgvPVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BGinWm3-vPo4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}